{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Data from CSV\n",
    "\n",
    "This notebooks reads sample population data from `data/atlantis.csv` and plots it using Matplotlib. Edit `data/atlantis.csv` and re-run this cell to see how the plots change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sematch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m sematch.download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('../data/atlantis.csv')\n",
    "x = df['year']\n",
    "y = df['population']\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Population of Atlantis\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the texts into TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(['a&b','A&B', 'A AND B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between the vectors\n",
    "similarity = cosine_similarity(vectors)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# Load the BERT model\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the texts\n",
    "text1 = \"This is the first text.\"\n",
    "text2 = \"This is the second text.\"\n",
    "encoding1 = model.encode(text1, max_length=512)\n",
    "encoding2 = model.encode(text2, max_length=512)\n",
    "\n",
    "# Calculate the cosine similarity between the embeddings\n",
    "similarity = numpy.dot(encoding1, encoding2) / (numpy.linalg.norm(encoding1) * numpy.linalg.norm(encoding2))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext\n",
    "import fasttext\n",
    "\n",
    "# Load the FastText model\n",
    "model = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Preprocess the text\n",
    "text1 = 'This is a piece of text'\n",
    "text2 = 'This is another piece of text'\n",
    "tokens1 = fasttext.tokenize(text1)\n",
    "tokens2 = fasttext.tokenize(text2)\n",
    "tokens1 = [token.lower() for token in tokens1]\n",
    "tokens2 = [token.lower() for token in tokens2]\n",
    "\n",
    "# Generate word vectors for each piece of text\n",
    "vector1 = model.get_sentence_vector(tokens1)\n",
    "vector2 = model.get_sentence_vector(tokens2)\n",
    "\n",
    "# Calculate the similarity between the vectors using cosine similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "similarity = 1 - cosine(vector1, vector2)\n",
    "print('Similarity:', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Calculate the cosine similarity between two texts\n",
    "def cosine_similarity(text1, text2):\n",
    "  # Convert the texts to tensors\n",
    "  text1 = torch.tensor([text1])\n",
    "  text2 = torch.tensor([text2])\n",
    "\n",
    "  # Calculate the dot product of the texts\n",
    "  dot_product = torch.matmul(text1, text2.transpose(1, 0))\n",
    "\n",
    "  # Calculate the norms of the texts\n",
    "  norm1 = torch.norm(text1, dim=1)\n",
    "  norm2 = torch.norm(text2, dim=1)\n",
    "\n",
    "  # Calculate the cosine similarity\n",
    "  cosine_similarity = dot_product / (norm1 * norm2)\n",
    "\n",
    "  return cosine_similarity\n",
    "\n",
    "# Test the function\n",
    "text1 = \"The cat sat on the mat\"\n",
    "text2 = \"The cat slept on the bed\"\n",
    "text3 = \"The dog barked at the moon\"\n",
    "\n",
    "similarity1 = cosine_similarity(text1, text2)\n",
    "similarity2 = cosine_similarity(text1, text3)\n",
    "\n",
    "print(f\"Similarity between text1 and text2: {similarity1:.2f}\")\n",
    "print(f\"Similarity between text1 and text3: {similarity2:.2f}\")\n",
    "# Similarity between text1 and text2: 0.79\n",
    "# Similarity between text1 and text3: 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Calculate the cosine similarity between two texts\n",
    "def cosine_similarity(text1, text2):\n",
    "  # Convert the texts to tensors\n",
    "  text1 = torch.tensor([text1])\n",
    "  text2 = torch.tensor([text2])\n",
    "\n",
    "  # Calculate the dot product of the texts\n",
    "  dot_product = torch.matmul(text1, text2.transpose(1, 0))\n",
    "\n",
    "  # Calculate the norms of the texts\n",
    "  norm1 = torch.norm(text1, dim=1)\n",
    "  norm2 = torch.norm(text2, dim=1)\n",
    "\n",
    "  # Calculate the cosine similarity\n",
    "  cosine_similarity = dot_product / (norm1 * norm2)\n",
    "\n",
    "  return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "text1 = \"The cat sat on the mat\"\n",
    "text2 = \"The cat slept on the bed\"\n",
    "text3 = \"The dog barked at the moon\"\n",
    "\n",
    "similarity1 = cosine_similarity(text1, text2)\n",
    "similarity2 = cosine_similarity(text1, text3)\n",
    "\n",
    "print(f\"Similarity between text1 and text2: {similarity1:.2f}\")\n",
    "print(f\"Similarity between text1 and text3: {similarity2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "#nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=nlp(\"a & b\")\n",
    "w2=nlp(\"A & B\")\n",
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install sentence-transformers\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"source1.csv\") \n",
    "df2 = pd.read_csv(\"source2.csv\")\n",
    "\n",
    "source1_name_field = df1['name'].tolist()\n",
    "source2_customer_field = df2['customer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "emb_source1_name_field = model.encode(source1_name_field) \n",
    "emb_source1_name_field = model.encode(source2_customer_field)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(emb_source1_name_field, emb_source1_name_field)\n",
    "\n",
    "print(similarity)\n",
    "indices = np.argmax(similarity, axis=1)\n",
    "\n",
    "\n",
    "for i in range(len(indices)):\n",
    "  print(source1_name_field[i], source2_customer_field[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "sentence1 = \"Benson and Hedges\"\n",
    "sentence2 = \"Hedges AND Benson\"\n",
    "sentence3 = \"Hedges AND Benson\"\n",
    "sentence4 = \"HEDGES AND BENSON\"\n",
    "sentence5 = \"hedges & benson\"\n",
    "sentence6 = \"BENSON & HEDges\"\n",
    "sentence7 = \"Jack And Jill\"\n",
    "\n",
    "# Encode sentences to get their embeddings  \n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "embedding3 = model.encode(sentence3)\n",
    "embedding4 = model.encode(sentence4)\n",
    "embedding5 = model.encode(sentence5)\n",
    "embedding6 = model.encode(sentence6)\n",
    "embedding7 = model.encode(sentence7)\n",
    "embeddings=[embedding1,embedding2,embedding3,embedding4,embedding5,embedding6,embedding7]\n",
    "\n",
    "# Calculate cosine similarity between embeddings\n",
    "sim = cosine_similarity(embeddings)\n",
    "print(sim)\n",
    "print(\"Similarity score:\", sim[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.similarity(w2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
